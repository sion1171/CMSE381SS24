{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lec 12 Lab: The Lasso\n",
    "## CMSE 381 - Spring 2024\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90aa0b0",
   "metadata": {},
   "source": [
    "In this module we are going to test out the lasso method, discussed in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "\n",
    "# ML imports we've used previously\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9a257",
   "metadata": {},
   "source": [
    "# Loading in the data\n",
    "\n",
    "Ok, here we go, let's play with a baseball data set again. Note this cleanup is all the same as the last lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ceeb83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of original data: (322, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>League_N</th>\n",
       "      <th>Division_W</th>\n",
       "      <th>NewLeague_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks  PutOuts  Assists  Errors  Salary  League_N  Division_W  \\\n",
       "1   414     375      632       43      10   475.0         1           1   \n",
       "2   266     263      880       82      14   480.0         0           1   \n",
       "3   838     354      200       11       3   500.0         1           0   \n",
       "4    46      33      805       40       4    91.5         1           0   \n",
       "5   336     194      282      421      25   750.0         0           1   \n",
       "\n",
       "   NewLeague_N  \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "5            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitters_df = pd.read_csv('../../DataSets/Hitters.csv')\n",
    "\n",
    "# Print the dimensions of the original Hitters data (322 rows x 20 columns)\n",
    "print(\"Dimensions of original data:\", hitters_df.shape)\n",
    "\n",
    "# Drop any rows the contain missing values, along with the player names\n",
    "hitters_df = hitters_df.dropna().drop('Player', axis=1)\n",
    "\n",
    "# Replace any categorical variables with dummy variables\n",
    "hitters_df = pd.get_dummies(hitters_df, drop_first = True)\n",
    "\n",
    "hitters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4672d6f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 263 entries, 1 to 321\n",
      "Data columns (total 19 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   AtBat        263 non-null    float64\n",
      " 1   Hits         263 non-null    float64\n",
      " 2   HmRun        263 non-null    float64\n",
      " 3   Runs         263 non-null    float64\n",
      " 4   RBI          263 non-null    float64\n",
      " 5   Walks        263 non-null    float64\n",
      " 6   Years        263 non-null    float64\n",
      " 7   CAtBat       263 non-null    float64\n",
      " 8   CHits        263 non-null    float64\n",
      " 9   CHmRun       263 non-null    float64\n",
      " 10  CRuns        263 non-null    float64\n",
      " 11  CRBI         263 non-null    float64\n",
      " 12  CWalks       263 non-null    float64\n",
      " 13  PutOuts      263 non-null    float64\n",
      " 14  Assists      263 non-null    float64\n",
      " 15  Errors       263 non-null    float64\n",
      " 16  League_N     263 non-null    float64\n",
      " 17  Division_W   263 non-null    float64\n",
      " 18  NewLeague_N  263 non-null    float64\n",
      "dtypes: float64(19)\n",
      "memory usage: 41.1 KB\n"
     ]
    }
   ],
   "source": [
    "y = hitters_df.Salary\n",
    "\n",
    "# Drop the column with the independent variable (Salary)\n",
    "X = hitters_df.drop(['Salary'], axis = 1).astype('float64')\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76813de",
   "metadata": {},
   "source": [
    "Finally, here's a list of $\\alpha$s to test for our Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abbf296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000000e+03, 4.34874501e+03, 3.78231664e+03, 3.28966612e+03,\n",
       "       2.86118383e+03, 2.48851178e+03, 2.16438064e+03, 1.88246790e+03,\n",
       "       1.63727458e+03, 1.42401793e+03, 1.23853818e+03, 1.07721735e+03,\n",
       "       9.36908711e+02, 8.14875417e+02, 7.08737081e+02, 6.16423370e+02,\n",
       "       5.36133611e+02, 4.66301673e+02, 4.05565415e+02, 3.52740116e+02,\n",
       "       3.06795364e+02, 2.66834962e+02, 2.32079442e+02, 2.01850863e+02,\n",
       "       1.75559587e+02, 1.52692775e+02, 1.32804389e+02, 1.15506485e+02,\n",
       "       1.00461650e+02, 8.73764200e+01, 7.59955541e+01, 6.60970574e+01,\n",
       "       5.74878498e+01, 5.00000000e+01, 4.34874501e+01, 3.78231664e+01,\n",
       "       3.28966612e+01, 2.86118383e+01, 2.48851178e+01, 2.16438064e+01,\n",
       "       1.88246790e+01, 1.63727458e+01, 1.42401793e+01, 1.23853818e+01,\n",
       "       1.07721735e+01, 9.36908711e+00, 8.14875417e+00, 7.08737081e+00,\n",
       "       6.16423370e+00, 5.36133611e+00, 4.66301673e+00, 4.05565415e+00,\n",
       "       3.52740116e+00, 3.06795364e+00, 2.66834962e+00, 2.32079442e+00,\n",
       "       2.01850863e+00, 1.75559587e+00, 1.52692775e+00, 1.32804389e+00,\n",
       "       1.15506485e+00, 1.00461650e+00, 8.73764200e-01, 7.59955541e-01,\n",
       "       6.60970574e-01, 5.74878498e-01, 5.00000000e-01, 4.34874501e-01,\n",
       "       3.78231664e-01, 3.28966612e-01, 2.86118383e-01, 2.48851178e-01,\n",
       "       2.16438064e-01, 1.88246790e-01, 1.63727458e-01, 1.42401793e-01,\n",
       "       1.23853818e-01, 1.07721735e-01, 9.36908711e-02, 8.14875417e-02,\n",
       "       7.08737081e-02, 6.16423370e-02, 5.36133611e-02, 4.66301673e-02,\n",
       "       4.05565415e-02, 3.52740116e-02, 3.06795364e-02, 2.66834962e-02,\n",
       "       2.32079442e-02, 2.01850863e-02, 1.75559587e-02, 1.52692775e-02,\n",
       "       1.32804389e-02, 1.15506485e-02, 1.00461650e-02, 8.73764200e-03,\n",
       "       7.59955541e-03, 6.60970574e-03, 5.74878498e-03, 5.00000000e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of alphas\n",
    "alphas = 10**np.linspace(4,-2,100)*0.5\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b69746",
   "metadata": {},
   "source": [
    "# Lasso \n",
    "\n",
    "Thanks to the wonders of `scikit-learn`, now that we know how to do all this with ridge regression, translation to lasso is super easy. \n",
    "\n",
    "- [Lasso Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "- [LassoCV Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV)\n",
    "- [User guide](https://scikit-learn.org/stable/modules/linear_model.html#lasso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe822edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e181b9",
   "metadata": {},
   "source": [
    "Here's an example computing the lasso regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 #<------ this is me picking an alpha value\n",
    "\n",
    "# normalize the input\n",
    "transformer = StandardScaler().fit(X)\n",
    "# transformer.set_output(transform = 'pandas') #<---- some older versions of sklearn\n",
    "                                               #      have issues with this\n",
    "X_norm = pd.DataFrame(transformer.transform(X), columns = X.columns)\n",
    "\n",
    "# Fit the regression\n",
    "lasso = Lasso(alpha = a) \n",
    "lasso.fit(X_norm, y)\n",
    "\n",
    "# Get all the coefficients\n",
    "print('intercept:', lasso.intercept_)\n",
    "print('\\n')\n",
    "print(pd.Series(lasso.coef_, index = X_norm.columns))\n",
    "print('\\nTraining MSE:',mean_squared_error(y,lasso.predict(X_norm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c2da4",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Mess with the values for $a$ in the code, such as for $a=1, 10, 100, 1000$. What do you notice about the coefficients? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63a093",
   "metadata": {},
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4929bd",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Make a graph of the coeffiencts from lasso as $\\alpha$ changes \n",
    "\n",
    "*Note: we did similar things in the last class, I've included the code you can borrow and modify from there. Also note I got a bunch of convergence warnings, but drawing the graphs I could safely ignore them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1463365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for computing the coefficients goes here \n",
    "# I've included the code from last class that did this for the ridge version\n",
    "# so you should just need to update it to do lasso instead.\n",
    "\n",
    "\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha = a) \n",
    "    ridge.fit(X_norm, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "\n",
    "coefs = pd.DataFrame(coefs,columns = X_norm.columns)\n",
    "coefs.head()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900f7150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If that worked above, you'll get a graph in this code. \n",
    "\n",
    "for var in coefs.columns:\n",
    "    # I'm greying out the ones that have magnitude below 200 to easier visualization\n",
    "    if np.abs(coefs[var][coefs.shape[0]-1])<200:\n",
    "        plt.plot(alphas, coefs[var], color = 'grey', linewidth = .5)\n",
    "    else:\n",
    "        plt.plot(alphas, coefs[var], label = var)\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coefficients')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656dec1",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Make a graph the test mean squared error as $\\alpha$ changes for a fixed train/test split. \n",
    "\n",
    "*Note: again I've included code from last time that you should just have to update.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this code to get the MSE for lasso instead of Ridge\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "errors = []\n",
    "transformer = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_norm = pd.DataFrame(transformer.transform(X_train), columns = X.columns)\n",
    "X_test_norm = pd.DataFrame(transformer.transform(X_test), columns = X.columns)\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha = a) \n",
    "    ridge.fit(X_train_norm, y_train)\n",
    "\n",
    "    pred = ridge.predict(X_test_norm)\n",
    "    errors.append(mean_squared_error(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ec63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If that worked, you should see your test error here.\n",
    "i = np.argmin(errors) # Index of minimum \n",
    "print('Min occurs at alpha = ', alphas[i])\n",
    "print('Min MSE is', errors[i])\n",
    "\n",
    "plt.title('Testing MSE')\n",
    "plt.plot(alphas,errors)\n",
    "plt.scatter(alphas[i],errors[i])\n",
    "ax=plt.gca()\n",
    "ax.set_xscale('log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238b939",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** make a plot showing the number of non-zero coefficients in each model.\n",
    "\n",
    "*Hint: I used the `np.count_nonzero` command*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2b61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e8c64c",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** Say your goal was to end up with a model with 5 variables used. What choice of $\\alpha$ gives us that and what are the variables used?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b7ab6",
   "metadata": {},
   "source": [
    "## Lasso with Cross Validation\n",
    "\n",
    "&#9989; **<font color=red>Do this:</font>** Now try what we did with `LassoCV`.  What choice of $\\alpha$ does it recommend? \n",
    "\n",
    "*I would actually recommend either not passing in any $\\alpha$ list or passing explicitly `alphas = None`. `RidgeCV` can't do this, but `LassoCV` will automatically try to find good choices of $\\alpha$ for you.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the ridge code from last time that you should update\n",
    "\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# To make sure my normalization isn't snooping, I fit the transformer only \n",
    "# on the training set \n",
    "transformer = StandardScaler().fit(X_train)\n",
    "# transformer.set_output(transform = 'pandas')\n",
    "X_train_norm = pd.DataFrame(transformer.transform(X_train), columns = X_train.columns)\n",
    "\n",
    "# but in order for my output results to make sense, I have to apply the same \n",
    "# transformation to the testing set. \n",
    "X_test_norm = transformer.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "ridgecv = RidgeCV(alphas = alphas, \n",
    "                  scoring = 'neg_mean_squared_error', \n",
    "                  )\n",
    "ridgecv.fit(X_train_norm, y_train)\n",
    "\n",
    "print('alpha chosen is', ridgecv.alpha_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe50336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d3ee5d",
   "metadata": {},
   "source": [
    "Now let's take a look at some of the coefficients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691eabf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Some of the coefficients are now reduced to exactly zero.\n",
    "pd.Series(lassocv.coef_, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b02f1",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Q:</font>** We've been repeating over and over that lasso gives us coefficients that are actually 0.  At least in my code, I'm not seeing many that are 0. What happened? Can I change something to get more 0 entries? \n",
    "\n",
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might also want some code in here to try to figure it out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
